# API Классификатора Токсичных Комментариев

## Описание

Это FastAPI-сервис, который предоставляет HTTP-эндпоинт для анализа русскоязычного текста на предмет токсичности. API использует легковесную CNN-модель (~5 МБ), оптимизированную для быстрого инференса на CPU.

## Быстрый старт (Локальная разработка)

Все команды выполняются из **корневой папки проекта** (`AI_Toxic/`).

1.  **Создайте и активируйте виртуальное окружение:**
    ```bash
    python -m venv venv
    # Для Windows: venv\Scripts\activate
    # Для macOS/Linux: source venv/bin/activate
    ```

2.  **Установите зависимости:**
    ```bash
    pip install -r api/requirements.txt
    ```

3.  **Запустите API сервер:**
    ```bash
    uvicorn api.main:app --reload
    ```

4.  **Откройте документацию:**
    Перейдите в браузере по адресу [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs) для просмотра интерактивной документации Swagger UI.

## Запуск с помощью Docker (Продакшен)

1.  **Соберите Docker-образ** (выполняется из корневой папки `AI_Toxic/`):
    ```bash
    docker build -t toxic-classifier-api . -f api/Dockerfile
    ```

2.  **Запустите контейнер:**
    ```bash
    docker run -d -p 8000:8000 --name my-toxic-api toxic-classifier-api
    ```
    API будет доступно по адресу `http://localhost:8000`.

## Эндпоинты API

### Проверка состояния

-   **GET /**
    -   **Описание:** Проверяет, что API запущено и работает.
    -   **Ответ (`200 OK`):**
        ```json
        {
          "status": "ok",
          "message": "API is running."
        }
        ```

### Классификация текста

-   **POST /predict**
    -   **Описание:** Анализирует переданный текст и возвращает оценку токсичности.
    -   **Тело запроса (Request Body):**
        ```json
        {
          "text": "Текст вашего комментария для проверки."
        }
        ```
    -   **Параметры URL (Query Parameters):**
        -   `threshold` (float, опционально, по умолчанию: `0.5`): Порог уверенности для принятия решения `is_toxic`.
    -   **Ответ (`200 OK`):**
        ```json
        {
          "is_toxic": true,
          "toxic_score": 0.9081,
          "text": "Текст вашего комментария для проверки."
        }
        ```
    -   **Пример использования с `curl`:**
        ```bash
        curl -X POST "http://127.0.0.1:8000/predict?threshold=0.4" \
        -H "Content-Type: application/json" \
        -d '{"text": "автор ты неправ и пишешь какую-то чушь"}'
        ```

## Конфигурация

-   **Версия модели:** Загружается из `models/v1.0/`. Путь к модели настраивается в файле `api/config.py`.