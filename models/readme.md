================================================================================
Проект: Легковесный классификатор токсичных комментариев
Дата: Сентябрь 2025
Автор: [Ваше Имя/Никнейм]
Датасет: Toxic Russian Comments from Pikabu and 2ch (Kaggle)
================================================================================


### ЧТО ЭТО? (Цель проекта) ###

Это проект по созданию **сверхлегковесной** модели для классификации токсичности в русскоязычных комментариях.

**Главная цель:** Создать модель, которая будет:
1.  **Маленькой:** Итоговый размер на диске должен быть минимальным (~5-10 МБ).
2.  **Быстрой:** Время предсказания (inference) на CPU должно быть в пределах миллисекунд.
3.  **Автономной:** Модель не должна зависеть от тяжелых библиотек вроде transformers.
4.  **Готовой к продакшену:** Подходящей для встраивания в API, Telegram-бота или другое приложение с ограниченными ресурсами.


### КАК ЭТО СДЕЛАНО? (Ключевые решения и методология) ###

Модель была создана с нуля ("сольная" CNN) и прошла через несколько итераций отладки и улучшения.

**1. Предобработка текста (Токенизация):**
   - **Первоначальная идея:** Использовать библиотеку `natasha` для лемматизации.
   - **Проблема:** В среде Kaggle `natasha` не смогла корректно лемматизировать слова.
   - **Финальное решение:** Использовать `natasha.Segmenter` для лингвистически правильного разделения текста на слова (токены), с последующей очисткой и приведением к нижнему регистру.

**2. Архитектура модели (Solo CNN):**
   - **Основа:** Классическая архитектура CNN для текста с несколькими параллельными сверточными слоями (ядра 3, 4, 5) и Max-Pooling.
   - **Стабилизация:** Для стабильного обучения и совместимости с квантизацией были добавлены `nn.BatchNorm1d`, `nn.ReLU` (как модуль), а также "мосты" `QuantStub` и `DeQuantStub`.

**3. Процесс обучения:**
   - **Решение проблем сходимости:** Снижен `learning_rate` до `2e-4`, добавлен планировщик `CosineAnnealingLR` и `gradient clipping`. Веса классов (`class_weights`) были убраны, так как приводили к коллапсу модели.

**4. Оптимизация (Квантизация):**
   - **Процесс:** Post Training Static Quantization.
   - **Ключевые исправления:** Применена специальная конфигурация для `nn.Embedding` и добавлен явный шаг слияния модулей (`torch.quantization.fuse_modules`) для паттерна `Conv-BN-ReLU`.


### КОНФИГУРАЦИЯ И ПАРАМЕТРЫ ###

Ключевые параметры, использованные для обучения лучшей модели и необходимые для инференса:

**Параметры предобработки:**
- **VOCAB_SIZE:** 20000 (размер словаря)
- **MAX_SEQ_LEN:** 128 (максимальная длина последовательности токенов)

**Архитектура модели:**
- **EMBED_DIM:** 256 (размерность векторов слов)
- **NUM_FILTERS:** 256 (количество сверточных фильтров)
- **KERNEL_SIZES:** (размеры ядер сверток)
- **DROPOUT_RATE:** 0.3


### ФИНАЛЬНЫЕ РЕЗУЛЬТАТЫ И ИСПОЛЬЗОВАНИЕ ###

#### Результаты ####

- **Модель:** Квантованная (INT8) "сольная" CNN.
- **Размер на диске:** **~5 МБ**.
- **Качество (лучшая модель v1.0):** F1-score (токсичный класс) ~0.58.
  - **Precision:** 0.68 (когда модель говорит "токсично", она права в 68% случаев).
  - **Recall:** 0.51 (модель находит 51% всех токсичных комментариев).

#### Важность настройки порога (threshold) ####

Модель выдает не просто ответ "да/нет", а **вероятность** токсичности от 0.0 до 1.0 (параметр `toxic_score`). Порог (`threshold`) — это "планка уверенности", которую мы устанавливаем, чтобы принять решение.

**`is_toxic = toxic_score > threshold`**

Значение `threshold=0.5` является стандартной отправной точкой, но почти никогда не является оптимальным для реальной задачи. Управляя этим параметром, вы управляете поведением вашего бота/API:

-   **НИЗКИЙ ПОРОГ (например, `threshold=0.35`):**
    -   **Поведение:** Модель становится более "бдительной" и "параноидальной".
    -   **Плюсы:** Находит больше токсичных комментариев (**Recall увеличивается**).
    -   **Минусы:** Чаще ошибается, помечая нормальные комментарии как токсичные (**Precision падает**).
    -   **Когда использовать:** Для систем предварительной модерации, где все подозрительные комментарии отправляются на проверку человеку.

-   **ВЫСОКИЙ ПОРОГ (например, `threshold=0.7`):**
    -   **Поведение:** Модель становится более "осторожной" и "уверенной в себе".
    -   **Плюсы:** Если модель пометила комментарий, она почти наверняка права (**Precision увеличивается**). Меньше ложных обвинений.
    -   **Минусы:** Пропускает много пограничных и не самых очевидных токсичных комментариев (**Recall падает**).
    -   **Когда использовать:** Для полностью автоматических систем, где наказание за ошибку высокое (например, автоматический бан).

**Рекомендация:** Начните с `0.5`, но обязательно подберите значение, которое дает наилучший баланс для вашей конкретной задачи.

#### Пайплайн для инференса (Inference) ####

Для работы модели нужны 3 артефакта: `solo_cnn_int8.pth`, `vocab.json` и следующий код.

**Зависимости:** `torch`, `natasha`, `re`

**Полный самодостаточный код для предсказания:**

```python
import torch
import torch.nn.functional as F
import json
import re
from natasha import Segmenter, Doc

# --- ШАГ 1: Определение функций предобработки (должны быть идентичны тем, что при обучении) ---

segmenter = Segmenter()

def robust_tokenizer(text):
    if not isinstance(text, str) or not text.strip(): return []
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\@\w+', '', text)
    doc = Doc(text)
    doc.segment(segmenter)
    tokens = [token.text.lower() for token in doc.tokens if token.text.isalpha()]
    return tokens

def tokenize_text_robust(text, vocab, max_len):
    tokens = robust_tokenizer(text)
    indexed_tokens = [vocab.get(token, vocab.get('<unk>', 1)) for token in tokens]
    padding = [vocab.get('<pad>', 0)] * (max_len - len(indexed_tokens))
    indexed_tokens = indexed_tokens[:max_len] + padding[:max(0, max_len - len(indexed_tokens))]
    return torch.tensor(indexed_tokens, dtype=torch.long)

# --- ШАГ 2: Загрузка артефактов ---

try:
    model = torch.jit.load('solo_cnn_int8.pth')
    model.eval()
    with open('vocab.json', 'r', encoding='utf-8') as f:
        vocab = json.load(f)
    print("Модель и словарь успешно загружены.")
except FileNotFoundError:
    print("Ошибка: Файлы 'solo_cnn_int8.pth' и 'vocab.json' должны находиться в той же папке.")
    exit()

# --- ШАГ 3: Функция для предсказания ---

def predict(text, threshold=0.5): # <-- ЭТОТ ПАРАМЕТР НУЖНО НАСТРАИВАТЬ!
    """
    Принимает сырой текст и возвращает словарь с результатом.
    """
    input_ids = tokenize_text_robust(text, vocab, max_len=128).unsqueeze(0)
    with torch.no_grad():
        logits = model(input_ids)
        probabilities = F.softmax(logits, dim=1).squeeze()
    
    if probabilities.dim() == 0:
        score_toxic = probabilities.item()
    else:
        score_toxic = probabilities[1].item()
        
    is_toxic = score_toxic > threshold
    return {"is_toxic": is_toxic, "toxic_score": f"{score_toxic:.4f}"}

# --- ШАГ 4: Пример вызова ---

print("\n--- Тестовые предсказания ---")
print(predict("автор ты просто гений и молодец"))
print(predict("автор ты просто идиот и пишешь чушь"))
print(predict("Это просто худший сервис из всех, что я пробовал.", threshold=0.4)) # Пример с измененным порогом
```

### Заключение ###
Этот проект — пример создания production-ready NLP модели с экстремально низкими требованиями к ресурсам. Модель идеально подходит для высоконагруженных API, ботов и даже для запуска на мобильных устройствах.