# Jupyter Notebooks: Обучение и исследование

Этот каталог содержит Jupyter Notebooks, которые использовались для исследования, экспериментов и создания финальной модели классификации токсичных комментариев.

## Описание

Здесь находится "сердце" ML-разработки этого проекта. Блокноты в этой папке демонстрируют полный цикл работы: от загрузки и анализа данных до обучения, отладки и финальной оптимизации модели.

---

### Список блокнотов

#### 1. `cnn_training.ipynb`

-   **Ссылка:** [`cnn_training.ipynb`](./cnn_training.ipynb)
-   **Описание:** Это основной и единственный блокнот проекта, который реализует полный end-to-end пайплайн:
    1.  **Загрузка данных:** Чтение исходного `dataset.csv`.
    2.  **Предобработка текста:** Создание словаря и функций токенизации с использованием библиотеки `natasha` в "надежном" режиме (без лемматизации).
    3.  **Архитектура модели:** Определение "сольной" CNN модели на PyTorch, включая все слои, необходимые для стабилизации обучения и последующей квантизации (`BatchNorm1d`, `ReLU` как модуль, `QuantStub`/`DeQuantStub`).
    4.  **Обучение и валидация:** Полный цикл обучения с планировщиком скорости обучения, отслеживанием метрик (`F1-score`) и сохранением лучшей модели.
    5.  **Оценка:** Финальная оценка лучшей FP32-модели с построением отчета и матрицы ошибок.
    6.  **Оптимизация:** Процесс Post-Training Static Quantization для преобразования модели в легковесный INT8 формат, включая обязательный шаг слияния модулей (`fuse_modules`).
    7.  **Тестирование:** Финальная проверка работоспособности квантованной модели.

---

## Настройка и запуск

Для воспроизведения результатов, изложенных в блокноте, следуйте этим шагам. Все команды выполняются из **корневой папки проекта (`AI_Toxic/`)**.

### 1. Требования

Рекомендуется создать отдельный файл с зависимостями для Jupyter-среды.

**Создание `requirements-notebooks.txt`:**
```bash
# (Предполагается, что вы уже установили все в venv)
# Активируйте venv и выполните:
pip freeze > notebooks/requirements.txt
```

**Минимальный список зависимостей для запуска:**
- `jupyterlab` (или `notebook`)
- `pandas`
- `scikit-learn`
- `torch`
- `natasha`
- `tqdm`

### 2. Инструкции по запуску

1.  **Убедитесь, что вы находитесь в корне проекта `AI_Toxic/`**.
2.  **Активируйте ваше виртуальное окружение:**
    ```bash
    # Для Windows: venv\Scripts\activate
    # Для macOS/Linux: source venv/bin/activate
    ```
3.  **Установите зависимости (если еще не установлены):**
    ```bash
    pip install -r notebooks/requirements.txt
    ```
4.  **Запустите Jupyter Lab (рекомендуется) или Jupyter Notebook:**
    ```bash
    jupyter lab
    # или
    # jupyter notebook
    ```
5.  В открывшемся интерфейсе в браузере перейдите в папку `notebooks/` и откройте файл `cnn_training.ipynb`.
6.  Вы можете выполнять ячейки последовательно, чтобы воспроизвести весь процесс.

---

## Ключевые выводы и артефакты

### Основные моменты исследования

В ходе работы над моделью были выявлены и решены несколько ключевых технических проблем:
-   **Проблема с `natasha`:** Лемматизация в облачной среде Kaggle оказалась нестабильной, что потребовало перехода на более надежный метод токенизации.
-   **Нестабильность обучения:** Модель была склонна к "коллапсу" (предсказание одного класса). Проблема была решена с помощью комбинации `BatchNorm1d`, `ReLU` как модуля, планировщика скорости обучения и `gradient clipping`.
-   **Сложности квантизации:** Успешная квантизация потребовала многоступенчатой отладки, включая явное слияние модулей `Conv-BN-ReLU` и использование "мостов" `QuantStub`/`DeQuantStub`.

### Генерируемые артефакты

При полном выполнении блокнот `cnn_training.ipynb` создает и сохраняет следующие артефакты в директорию `models/v1.0/`:

1.  `solo_cnn_fp32.pth` — "Мастер-модель" для дообучения.
2.  `solo_cnn_int8.pth` — Квантованная модель для инференса.
3.  `vocab.json` — Словарь для токенизации.
``````
